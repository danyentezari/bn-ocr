{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obI7x309JZl7"
      },
      "outputs": [],
      "source": [
        "!pip install keras==2.2.5\n",
        "!pip install tensorflow==1.13.1\n",
        "!unzip kaggle.json.zip\n",
        "!mkdir ~/.kaggle \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download scolianni/mnistasjpg\n",
        "!unzip mnistasjpg.zip\n",
        "!pip install keras==2.2.5\n",
        "!pip install tensorflow==1.13.1\n",
        "!pip install 'h5py==2.10.0' --force-reinstall\n",
        "!pip install cairocffi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq_h85uJ60oR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import re\n",
        "from scipy.sparse import csr_matrix\n",
        "import cv2\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "import string\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "import itertools\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmvD6G93A82e"
      },
      "outputs": [],
      "source": [
        "alphabet = '0123456789'\n",
        "# def encode_to_labels(txt):\n",
        "#     # encoding each output word into digits\n",
        "#     dig_lst = []\n",
        "#     for index, char in enumerate(txt):\n",
        "#         if char in char_list:\n",
        "#             dig_lst.append(char_list.index(char))\n",
        "#         # else:\n",
        "#         #   print(char)\n",
        "#     return dig_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpM3L7zO8SnO"
      },
      "outputs": [],
      "source": [
        "def labels_to_text(labels, alphabet):\n",
        "    \"\"\"Reverse translation of numerical classes back to characters.\"\"\"\n",
        "    ret = []\n",
        "    for c in labels:\n",
        "        if c == len(alphabet):  # CTC Blank\n",
        "            ret.append(\"\")\n",
        "        else:\n",
        "            ret.append(alphabet[c])\n",
        "    return \"\".join(ret)\n",
        "\n",
        "\n",
        "def text_to_labels(text, alphabet):\n",
        "    \"\"\" Translation of characters to unique integer values\n",
        "    \"\"\"\n",
        "    ret = []\n",
        "    for char in text:\n",
        "        ret.append(alphabet.find(char))\n",
        "    return ret\n",
        "\n",
        "\n",
        "def decode_batch(test_func, word_batch, alphabet):\n",
        "    \"\"\"\n",
        "    - Greedy search -\n",
        "    For a real OCR application, this should be beam\n",
        "    search with a dictionary and language model.\n",
        "    For this example, best path is sufficient.\n",
        "    \"\"\"\n",
        "    res = []\n",
        "    prob = []\n",
        "    out = test_func([word_batch])[0]\n",
        "    for i in range(out.shape[0]):\n",
        "        out_best = list(np.argmax(out[i, 2:], 1))\n",
        "        out_prob = np.mean(np.max(out[i, 2:], 1))\n",
        "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
        "        outstr = labels_to_text(out_best, alphabet)\n",
        "        res.append(outstr)\n",
        "        prob.append(out_prob)\n",
        "    return res, prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zafSq78C7JS0",
        "outputId": "a64743e9-bbab-4d4c-cebb-dcbef5d0722c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq3lRg-x7Jie"
      },
      "outputs": [],
      "source": [
        "# # # Get features\n",
        "# !gdown https://drive.google.com/uc?id=176PKaCUDWmTJdQwc-OfkO0y8t4gLsIvQ\n",
        "# !unzip formulae.zip\n",
        "\n",
        "# # # Get labels\n",
        "# !gdown https://drive.google.com/uc?id=1QUjX6PFWPa-HBWdcY-7bA5TRVUnbyS1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO-6EznR7NK7"
      },
      "outputs": [],
      "source": [
        "# alphabet = string.digits + \\\n",
        "#            string.ascii_lowercase + \\\n",
        "#            string.ascii_uppercase + \\\n",
        "#            '\\n' + \\\n",
        "#            '\\t' + \\\n",
        "#            \"\".join([' ', '~', ':', \"'\", '+', '[', '\\\\', '@', '^', '{', '%', '(', '-', '\"', '*', '|', ',', '&', '<', '`', '}', '.', '_', '=', ']', '!', '>', ';', '?', '#', '$', ')', '/'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1HL-lIrl_3J"
      },
      "outputs": [],
      "source": [
        "def loadImage(filepath):\n",
        "  img = load_img(filepath)\n",
        "  img = img_to_array(img)\n",
        "  # img = img.reshape(1, 448, 64, 3)\n",
        "  # img = img.reshape(64, 192, 3)\n",
        "  img = img.astype('float32')\n",
        "  img = img / 255.0\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZjafOnBskSaP"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "ch = 28\n",
        "cw = 28\n",
        "\n",
        "data_F = np.empty((0, ch, cw, 3))\n",
        "data_L = np.empty((0))\n",
        "\n",
        "i = 0\n",
        "for f_label in listdir('./trainingSet/trainingSet'):\n",
        "  for img_name in listdir(f'./trainingSet/trainingSet/{f_label}'):\n",
        "    img = loadImage(f'./trainingSet/trainingSet/{f_label}/{img_name}')\n",
        "\n",
        "    # if i == 1:\n",
        "    #   break\n",
        "\n",
        "    # print(np.array([img]).shape)\n",
        "    # print(data_F.shape)\n",
        "    # i = 1\n",
        "\n",
        "    data_F = np.append(data_F, [img], axis=0)\n",
        "    data_L = np.append(data_L, [f_label], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "KdN-6Yc1bZ8u"
      },
      "outputs": [],
      "source": [
        "data_L_dist = to_categorical(data_L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "85_0abkw7Oxa",
        "outputId": "27e2cf3d-cb96-432c-d437-68e9a7fc3d4b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAD5klEQVR4nO1VO0graxCe/feZbFxDHorERoKFB8RKiEgEGyt7I4ggWNiksbG1EsHCSrtUgiJYWajgAyxEGysVxMJCwaAxJiRu9r1ziznZG3NzuNXt7hQh++/833wz880s8DwPAADA87wsy/RIv6qqBq+CP4qitB0CAGMM/tU4jhNFEQAikQgARKNROhcEgSAURSFQQRCCMO3WGorjOMYYx3GEGNyRJKmVviRJsiz/kSPHcUEujLHWvAgXAHp7e1uvqKoauBH9H4AECgCISKC+7xMR27b7+voYY/l8HhFHR0cLhYLjOFdXV8ViEQB4nvd9ny7+sH/GIeN5PpfLGYbx+fmJiJZl2bb9+vparVbX19cHBweJCmOsQwWCo9Z0UqnU5eWl4zie52GLVatVovbw8DA7O0v+mqZRgA5GfQCAWCyWyWQajQYiep5Xr9cdx0FEXdcJmnCLxeLKyoosywBAUumQfiQS6erqAoDJycmLiwsCRURCzOfzuVzu+voaEQ3DsG0bET8+Pubm5jpzDIfDAf9YLLazs2OaJiKWSqXHx8ft7e3V1dXh4WFJkhRF6enpub+/p3iu6x4cHABAd3d3OyjHcYIgBCmcnp5SjvPz82NjY7IsU8igPhsbG7VajXCfnp4mJibaEUVRDHqlqmomk3Fdt1QqeZ6XSCTorSiKhEtzAQALCwuWZZmmaVnW7u5u21Axx3F83ydXXdc1TeN5PpFImKYpiqIoir7vO45D3sHs7+/vS5Lk+z7Hcbqum6b5gynBybJMwzMzM/Py8oKIJycn0NRZOBxu7W8oFAKA4+Nj6uHz83OHmgbZxePxt7c3RKzX64iYTqfbhB0KhYJMp6amdF2n4mqa1uomAAAiMsY8zwOAZDJZrVaj0ahpmkQEmrILh8O1Wg2ao/z+/h4OhwHANE1S69/ZS5Lkui7hlsvlw8NDRVE8z6O5pkxd1xUEgRADGSQSCdu2AUBRFMMw2tMnPypfLpcLBH92dpZMJqEpQ0VRGGO0W9Pp9M3NjWEYjuOsra11WCA8z/M8T2VVVfXu7s4wDMuyEPH8/Hx6evp3pZobmrpPOjUMY2RkpDPN37VgDADGx8dvb29pfSDi0dHR0NBQJpPp7+8fGBj49etXpVJpNBqO43x9fRUKBWguz5aiMhYcMcao9ktLS5VKJcD1PM8wjHK5TOxo8MlhcXGxAyg9B3uP+igIwvLycuvSo4J4nkfDUi6XHccJtl/n1Uddpte0qzRN29vbQ8RGoxFsVd/3SZjf39/ZbBYA4vH4H9MPhEbdIDGnUqlsNru5uRnsJETc2tpKJpOSJAWf2DaR/m//if0F9y0+HgsnqwkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F127EC07A10>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_image = loadImage('./trainingSet/trainingSet/0/img_1.jpg')\n",
        "Image.fromarray(np.uint8(sample_image*255)).convert('RGB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXCR8ROH7ep6"
      },
      "source": [
        "### Features and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2nWSEqY7lbC",
        "outputId": "f1dd3d5c-f83d-444e-b26e-dde853ed9077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 28, 28, 3)\n",
            "(42000,)\n",
            "(42000, 10)\n"
          ]
        }
      ],
      "source": [
        "print(data_F.shape)\n",
        "print(data_L.shape)\n",
        "print(data_L_dist.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dI90D4d77n60"
      },
      "outputs": [],
      "source": [
        "# train_L_id = np.array([np.zeros(max_word_length_track)])\n",
        "# train_L_t = []\n",
        "\n",
        "# for i,label in enumerate(train_L):\n",
        "#   ids = np.zeros(max_word_length_track)\n",
        "#   new_item = [float(alphabet_t2id[t]) for i,t in enumerate(list(label))]\n",
        "#   ids[0: len(new_item)] = new_item\n",
        "#   train_L_id = np.append(train_L_id, [ids], axis=0)\n",
        "\n",
        "\n",
        "# # train_L_id = np.delete(train_L_id, [0])\n",
        "# train_L_id = train_L_id[1:]\n",
        "# len(train_L_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3mlAF8Q7ocC"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw-VdKyhZaNE",
        "outputId": "ccef339a-c838-4b06-bdd9-0b3cbe12d9da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          (None, 28, 28, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 28, 28, 16)   448         the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max1 (MaxPooling2D)             (None, 14, 14, 16)   0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 14, 14, 16)   2320        max1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "max2 (MaxPooling2D)             (None, 7, 7, 16)     0           conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 7, 112)       0           max2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 7, 32)        3616        reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru1 (GRU)                      (None, 7, 512)       837120      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru1_b (GRU)                    (None, 7, 512)       837120      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 7, 512)       0           gru1[0][0]                       \n",
            "                                                                 gru1_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru2 (GRU)                      (None, 7, 512)       1574400     add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru2_b (GRU)                    (None, 7, 512)       1574400     add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 7, 1024)      0           gru2[0][0]                       \n",
            "                                                                 gru2_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 7, 10)        10250       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 7, 10)        0           dense2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 input_length[0][0]               \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,839,674\n",
            "Trainable params: 4,839,674\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import itertools\n",
        "import codecs\n",
        "import re\n",
        "import datetime\n",
        "import cairocffi as cairo\n",
        "import editdistance\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import pylab\n",
        "import tensorflow\n",
        "from keras import backend as K\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Input, Dense, Activation\n",
        "from keras.layers import Reshape, Lambda\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing import image\n",
        "import keras.callbacks\n",
        "#from keras.metrics import Metric\n",
        "from tensorflow.python.keras.metrics import Metric\n",
        "\n",
        "OUTPUT_DIR = 'image_ocr'\n",
        "\n",
        "\n",
        "def NNModel():\n",
        "  # Input Parameters\n",
        "  img_w = cw\n",
        "  img_h = ch\n",
        "  words_per_epoch = 16000\n",
        "  val_split = 0.2\n",
        "  val_words = int(words_per_epoch * (val_split))\n",
        "\n",
        "  # Network parameters\n",
        "  conv_filters = 16\n",
        "  kernel_size = (3, 3)\n",
        "  pool_size = 2\n",
        "  time_dense_size = 32\n",
        "  rnn_size = 512\n",
        "  minibatch_size = 32\n",
        "\n",
        "\n",
        "  input_shape = (ch, cw, 3)\n",
        "\n",
        "  act = 'relu'\n",
        "  input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
        "  inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
        "                  activation=act, kernel_initializer='he_normal',\n",
        "                  name='conv1')(input_data)\n",
        "  inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
        "  inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
        "                  activation=act, kernel_initializer='he_normal',\n",
        "                  name='conv2')(inner)\n",
        "  inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
        "\n",
        "  conv_to_rnn_dims = (img_w // (pool_size ** 2),\n",
        "                      (img_h // (pool_size ** 2)) * conv_filters)\n",
        "  inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
        "\n",
        "  # cuts down input size going into RNN:\n",
        "  inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
        "\n",
        "  # Two layers of bidirectional GRUs\n",
        "  # GRU seems to work as well, if not better than LSTM:\n",
        "  gru_1 = GRU(rnn_size, return_sequences=True,\n",
        "              kernel_initializer='he_normal', name='gru1')(inner)\n",
        "  gru_1b = GRU(rnn_size, return_sequences=True,\n",
        "                go_backwards=True, kernel_initializer='he_normal',\n",
        "                name='gru1_b')(inner)\n",
        "  gru1_merged = add([gru_1, gru_1b])\n",
        "  gru_2 = GRU(rnn_size, return_sequences=True,\n",
        "              kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
        "  gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True,\n",
        "                kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
        "\n",
        "  # transforms RNN output to character activations:\n",
        "  inner = Dense(\n",
        "      len(alphabet), \n",
        "      kernel_initializer='he_normal',\n",
        "      name='dense2')(concatenate([gru_2, gru_2b])\n",
        "    )\n",
        "  y_pred = Activation('softmax', name='softmax')(inner)\n",
        "\n",
        "\n",
        "\n",
        "  labels = Input(name='the_labels', shape=[1], dtype='float32')\n",
        "  input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "  label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "\n",
        "  # model0 = Model(\n",
        "  #     inputs=[input_data, labels, input_length, label_length],\n",
        "  #     outputs=y_pred\n",
        "  # )\n",
        "\n",
        "\n",
        "  def ctc_lambda_func(args):\n",
        "      y_pred, labels, input_length, label_length = args\n",
        "      # the 2 is critical here since the first couple outputs of the RNN\n",
        "      # tend to be garbage:\n",
        "      y_pred = y_pred[:, 2:, :]\n",
        "      return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "  # Keras doesn't currently support loss funcs with extra parameters\n",
        "  # so CTC loss is implemented in a lambda layer\n",
        "  loss_out = Lambda(\n",
        "      ctc_lambda_func, output_shape=(1,),\n",
        "      name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "  # clipnorm seems to speeds up convergence\n",
        "  sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "\n",
        "  model0 = Model(\n",
        "          inputs=[input_data, labels, input_length, label_length],\n",
        "          outputs=loss_out\n",
        "      )\n",
        "\n",
        "  model0.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam')\n",
        "\n",
        "\n",
        "  model0.summary()\n",
        "  train_model = model0\n",
        "\n",
        "  prediction_model = Model(inputs=input_data, outputs=y_pred)\n",
        "\n",
        "  return train_model, prediction_model\n",
        "\n",
        "\n",
        "model0, _ = NNModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaxECOCK8Zr1"
      },
      "outputs": [],
      "source": [
        "batch_size = 25 #a divisor of training length\n",
        "epochs = 5\n",
        "\n",
        "input_length = np.array([ [10] for i in range(len(train_F)) ])\n",
        "label_length = np.array([ [10] for i in range(len(train_F)) ])\n",
        "\n",
        "metrics0 = model0.fit(\n",
        "          x=[\n",
        "              train_F, \n",
        "              train_L_dist, \n",
        "              input_length,\n",
        "              label_length,\n",
        "            ], \n",
        "          # y = np.zeros(len(train_F)),\n",
        "          y = train_L_dist,\n",
        "          # batch_size=batch_size, \n",
        "          epochs = epochs, \n",
        "          # validation_data = ([val_img, val_padded_txt, val_input_length, val_label_length], val_padded_txt),\n",
        "          verbose = 2,\n",
        "          # callbacks = callbacks_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhAMGf8UTFgF"
      },
      "outputs": [],
      "source": [
        "model0.save_weights( './weights1-mnist.h5' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK1qdIDHdyVY"
      },
      "source": [
        "### Alternative Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "KfOMTtB1hcdF"
      },
      "outputs": [],
      "source": [
        "train_F, test_F, train_L_dist, test_L_dist = train_test_split(data_F, data_L_dist, test_size=0.1, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17RoiGw_hsWY",
        "outputId": "ae3a05a9-723c-44dc-d459-0dd85d61dc06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37800, 28, 28, 3), (4200, 28, 28, 3), (37800, 10), (4200, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "train_F.shape, test_F.shape, train_L_dist.shape, test_L_dist.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "uSttdlwhg4Nx"
      },
      "outputs": [],
      "source": [
        "# With data augmentation to prevent overfitting\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.01, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#datagen.fit(X_train)\n",
        "train_gen = datagen.flow(train_F, train_L_dist, batch_size=128)\n",
        "test_gen = datagen.flow(test_F, test_L_dist, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "map673iJhIgl"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "batch_size = 128\n",
        "train_steps = train_F.shape[0] // batch_size\n",
        "valid_steps = train_L_dist.shape[0] // batch_size\n",
        "\n",
        "es = keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_acc\", # metrics to monitor\n",
        "        patience=10, # how many epochs before stop\n",
        "        verbose=1,\n",
        "        mode=\"max\", # we need the maximum accuracy.\n",
        "        restore_best_weights=True, # \n",
        "     )\n",
        "\n",
        "rp = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_acc\",\n",
        "        factor=0.2,\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "        mode=\"max\",\n",
        "        min_lr=0.00001,\n",
        "     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "qmORo5YJdqLH"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Lambda, MaxPooling2D # convolution layers\n",
        "from keras.layers import Dense, Dropout, Flatten # core layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "model1=Sequential()\n",
        "\n",
        "#model1.add(Lambda(standardize,input_shape=(28,28,1)))    \n",
        "model1.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,3)))\n",
        "model1.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model1.add(BatchNormalization())\n",
        "\n",
        "model1.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
        "model1.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model1.add(BatchNormalization())    \n",
        "\n",
        "model1.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model1.add(BatchNormalization())\n",
        "    \n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(512,activation=\"relu\"))\n",
        "    \n",
        "model1.add(Dense(10,activation=\"softmax\"))\n",
        "    \n",
        "model1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3m3usj0eA-I",
        "outputId": "cf3a4108-3724-4a14-ba8f-0254ad100a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 39/295 [==>...........................] - ETA: 6:38 - loss: 0.5225 - acc: 0.8335"
          ]
        }
      ],
      "source": [
        "# metrics1 = model1.fit(x=train_F, y=train_L_dist, epochs=20, verbose=1)\n",
        "\n",
        "# Fit the model\n",
        "metrics1 = model1.fit_generator(train_gen, \n",
        "                              epochs = epochs, \n",
        "                              steps_per_epoch = train_steps,\n",
        "                              validation_data = test_gen,\n",
        "                              validation_steps = valid_steps, \n",
        "                              callbacks=[es, rp])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Zu6CyARjYj"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdzBBfKW6Uzy"
      },
      "outputs": [],
      "source": [
        "# pred = model0.predict(\n",
        "#     [train_F, train_L_id, np.array([1]), np.array([1])]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "chh_M6jWPUOh",
        "outputId": "561f6a6e-285f-4453-9e58-c7bed610fcc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f126e205910>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "img = train_F[9000]\n",
        "img = img.astype(np.uint8) \n",
        "plt.title(train_L[9000])\n",
        "plt.imshow(img * 255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSpEH8w27ryb",
        "outputId": "3237e0a4-f360-4014-fbd4-a8c40b3e8b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'model_weights' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/danyentezari/model_weights.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgkTA-AFTW6w"
      },
      "outputs": [],
      "source": [
        "_, model_infer = NNModel()\n",
        "# model_infer.load_weights(\"./model_weights/weights0-mnist.h5\")\n",
        "model_infer.load_weights(\"./weights1-mnist.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uUGXWN1QxYN"
      },
      "outputs": [],
      "source": [
        "# sample = train_F[0].reshape(1, 100, 780, 3)\n",
        "yhat = model_infer.predict(train_F[9000].reshape(1, ch, cw, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VwdmSAp17oE",
        "outputId": "ebf649c7-fab8-4391-c50f-b640331001be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 3, 2, 0, 0, 6, 0, 3, 0, 4]]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argmax(yhat, axis=1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmGyGKINSRON"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "keras-ocr-realvalues-bignumber-mnist.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}